\mainmatter

# Introduction {#c01-intro}

```{r}
#| label: globaloptions
#| include: FALSE
options(width=72)
```

Surveys are used to gather information about a population. These are often used by researchers, government agencies, and companies to better understand public opinion and behavior. For example, researchers at a non-profit might be interested in public opinion on a given topic, government agencies may be interested in behaviors to inform policy, or companies may survey potential consumers about their interests in a given product. Developing and fielding a survey is one way that organizations can gather information on their interests.

<!--Consider pulling out definitions into call out boxes or a glossary-->
This book focuses on how to **analyze** the data collected from a survey. Specially, we assume that you have conducted a survey or you are using a public use microdata file.  Microdata is data that has been publicly released and includes individual responses to surveys, analysis weights, and design variables. For the purposes of this book, we are assuming that you have weights and design variables for the survey data you are using as these are required to correctly calculate unbiased estimates^[If you do not already have weights created for the survey data you are using, we recommend reviewing other resources focused on weight creation such as @Valliant2018weights].  

To account for the weights and study design, researchers use statistical software such as SAS, Stata, SUDAAN, and R. This book will use R to provide an overview of how to conduct survey analysis. Our aim is to provide a comprehensive guide for individuals new to survey analysis but already have some background in statistics and R programming. We will use a combination of both the {survey} and {srvyr} packages and will present the code using the tidyverse best practices. 

In 2003, the {survey} package was released on CRAN and has been continuously developed over time^[https://cran.r-project.org/src/contrib/Archive/survey/]. This package, primarily developed by Thomas Lumley, is extensive and includes the following features:

- Estimates of point estimates and their associated variances, including means, totals, ratios, quantiles, and proportions
- Estimation of regression models, including generalized linear models, log-linear models, and survival curves
- Variances by Taylor linearization or by replicate weights (BRR, jackknife, bootstrap, multistage bootstrap, or user-supplied)
- Hypothesis testing for means, proportions, and more

The {srvyr} package in R builds on the {survey} package. It provides wrappers for functions that align with the tidyverse philosophy, which is our motivation for using and recommending this package. We believe it is easy to use for R users who already use {tidyverse} packages. For example, variables to many functions in the {survey} package are passed as formulas, but in the {srvyr} package, variable names are passed using tidy select^[https://dplyr.tidyverse.org/reference/dplyr_tidy_select.html] (a common feature in the tidyverse). Users of the tidyverse are most likely familiar with the magittr pipe (`%>%`) which will seemlessly work with functions from the {srvyr} package. Additionally, several common functions from {dplyr} can be applied to survey objects including `filter()`, `mutate()`, and `summarize()`. 

There is one limitation to the {srvyr} package, the modeling functionality of the {survey} package is not ported over to tidy versions in the {srvyr} package. This book will use the {survey} package when discussing modeling and hypothesis testing, however, we will provide information on how to still pipe together the functions to make analyses that are easy to follow.  This book will cover all aspects of survey research, from understanding how to create the design effects, to conducing descriptive analysis, statistical testing, and modeling.  Additionally, we include best practices in coding and how to present results. Throughout this book we use real data and provide realistic examples to help you gain proficiency in survey analysis. While we do provide a brief overview of survey methodology and statistical theory, this book is not intended to be a sole resource for these topics.  We provide other references throughout the book and encourage readers who are interested to seek those out for more information. Here is an overview of each chapter:

- **Chapter \@ref(c02-overview-surveys)**: An overview of surveys and the process of designing surveys. This is only an overview, and we include many references to get more in-depth knowledge.
- **Chapter \@ref(c03-specifying-sample-designs)**: Specifying sampling designs. Descriptions of common sampling designs, when they are used, the math behind the mean and standard error estimates, how to specify the designs in R, and examples using real data.
- **Chapter \@ref(c04-understanding-survey-data-documentation)**: Understanding survey documentation. How to read the various components of survey documentation, working with missing data, and finding the documentation.
- **Chapter \@ref(c05-descriptive-analysis)**: Descriptive analyses. Calculating point estimates along with their standard errors, confidence intervals, and design effects.
- **Chapter \@ref(c06-statistical-testing)**: Statistical testing. Testing for differences between groups, including comparisons of means and proportions as well as goodness of fit tests, tests of independence, and tests of homogeneity.
- **Chapter \@ref(c07-modeling)**: Modeling. Linear regression, ANOVA, and logistic regression.
- **Chapter \@ref(c08-communicating-results)**: Communicating results. Describing results, reproducibility, making publishable tables and graphs, and helpful functions.
- **Chapter \@ref(c09-ncvs-vignette)**: National Crime Victimization Survey Vignette. A vignette on how to analyze data from the NCVS, a survey in the US that collects information on crimes and their characteristics. This illustrates an analysis that requires multiple files to calculate victimization rates.
- **Chapter \@ref(c10-ambarom-vignette)**: AmericasBarometer Vignette. A vignette on how to analyze data from the AmericasBarometer, a survey of attitudes, evaluations, experiences, and behavior in countries in the Western Hemisphere. This includes how to make choropleth maps with survey estimates.

Most chapters include code to follow along with.  Each chapter with this code will start with a set-up section.  This will include all of the code needed to load packages and datasets to use in the chapter.  We then provide an overview of the topic along with examples on how to use the functions.  Most chapters end with exercises to work through.  Solutions to these exercises can be found online at [XX].

The two main datasets we use throughout the book are the Residential Energy Consumption Survey [RECS -- @recs-2015-micro] and the American National Election Studies [ANES -- @debell].  To ensure that all readers can easily follow along with the examples, we have provided analytic datasets for readers on OSF^[https://osf.io/gzbkn/?view_only=8ca80573293b4e12b7f934a0f742b957]. To load any data used in the book that is not included in existing packages, we have created a helper function `read_osf()`. Here is the code to read in RECS and ANES datasets: 

```{r}
#| label: intro-setup
#| error: FALSE
#| warning: FALSE
#| message: FALSE
library(tidyverse)
library(survey)
library(srvyr)
library(osfr)
source("helper-fun/helper-functions.R")

recs_in <- read_osf("recs_2015.rds")
anes_in <- read_osf("anes_2020.rds")
```

RECS is a household study of energy consumption in the U.S. which provides energy consumption and expenditures data. RECS funded by Energy Information Administration and collects information through energy suppliers through in-person, phone, and web interviews. It has been fielded 14 times between 1950 and 2020 and includes questions about appliances, electronics, heating, air conditioning (A/C), temperatures, water heating, lighting, energy bills, respondent demographics, and energy assistance.  Here is an overview of the data we just read in `recs_in`:

```{r}
#| label: intro-recs
recs_in
```

From this ouput we can see that there are 5,686 rows and 141 variables.  We can see that there are variables containing an ID (`DOEID`), regional information (e.g., `Region`, `MSAStatus`), along with information about the house including the type of house (`HousingUnitType`) and when the house was built (`YearMade`). Additionally, there are a long list of weighting variables that will be used in the analysis (e.g., `NWEIGHT`, `BRRWT1`).  We will discuss how to use these weighting variables in chapter \@ref(c03-specifying-sample-designs).

The ANES is a times series study that has been collecting data from election surveys since 1948. These surveys contain data on public opinion and voting behavior in U.S. presidential elections. The 2020 survey (the data we will be using) was fielded in three modes (web, live video interviewing, or CATI) and asks respondents questions such as what their party affiliation is, who they voted for in the election, and their level of trust with the government. Here is an overview of the data we just read in `anes_in`:

```{r}
#| label: intro-anes
anes_in
```

From this ouput we can see that there are 7,543 rows and 42 variables.  Most of the variables start with V20, so referencing the documentation for survey will be crucial (see Chapter \@ref(c04-understanding-survey-data-documentation)).  We have created some more descriptive variables for you to use throughout this book such as the age (`Age`) and gender (`Gender`) of the respondent, along with variables that represent their party affiliation (`PartyID`). Additionally, there is a variable called `Weight` and a variable called `Stratum` that will be needed to accurately analyize this data.  We will discuss how to use these weighting variables in Chapters \@ref(c03-specifying-sample-designs) and \@ref(c04-understanding-survey-data-documentation).
